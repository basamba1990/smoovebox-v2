// supabase/functions/analyze-tone/index.js

import { createClient } from 'https://esm.sh/@supabase/supabase-js@2'

const corsHeaders = {
  'Access-Control-Allow-Origin': '*',
  'Access-Control-Allow-Headers': 'authorization, x-client-info, apikey, content-type',
}

export async function handler(req) {
  if (req.method === 'OPTIONS') {
    return new Response('ok', { headers: corsHeaders })
  }

  try {
    const supabase = createClient(
      Deno.env.get('SUPABASE_URL'),
      Deno.env.get('SUPABASE_SERVICE_ROLE_KEY')
    )

    const formData = await req.formData()
    const audioFile = formData.get('audio')
    const userId = formData.get('userId')

    if (!audioFile || !userId) {
      return new Response(
        JSON.stringify({ error: 'Fichier audio et utilisateur requis' }),
        { 
          status: 400, 
          headers: { ...corsHeaders, 'Content-Type': 'application/json' } 
        }
      )
    }

    console.log('üéµ D√©but analyse de tonalit√© pour user:', userId)

    // ‚úÖ OPTION 1: Utiliser Groq (recommand√© - tr√®s rapide)
    let toneAnalysis;
    try {
      toneAnalysis = await analyzeWithGroq(audioFile)
    } catch (groqError) {
      console.warn('‚ùå Erreur Groq, tentative Google AI:', groqError)
      try {
        toneAnalysis = await analyzeWithGoogleAI(audioFile)
      } catch (googleError) {
        console.warn('‚ùå Erreur Google AI, utilisation analyse basique:', googleError)
        toneAnalysis = getBasicToneAnalysis()
      }
    }

    return new Response(
      JSON.stringify({
        success: true,
        analysis: toneAnalysis
      }),
      { 
        status: 200, 
        headers: { ...corsHeaders, 'Content-Type': 'application/json' } 
      }
    )

  } catch (error) {
    console.error('‚ùå Erreur analyse tonalit√©:', error)
    
    return new Response(
      JSON.stringify({ 
        error: 'Erreur lors de l\'analyse de tonalit√©',
        details: error.message 
      }),
      { 
        status: 500, 
        headers: { ...corsHeaders, 'Content-Type': 'application/json' } 
      }
    )
  }
}

// ‚úÖ ANALYSE AVEC GROQ (Recommand√© - Rapide et gratuit)
async function analyzeWithGroq(audioFile) {
  const GROQ_API_KEY = Deno.env.get('GROQ_API_KEY')
  
  if (!GROQ_API_KEY) {
    throw new Error('Cl√© Groq non configur√©e')
  }

  // Convertir l'audio en base64 pour l'envoi
  const audioBuffer = await audioFile.arrayBuffer()
  const audioBase64 = arrayBufferToBase64(audioBuffer)

  // Prompt pour l'analyse de tonalit√© vocale
  const prompt = `
  Analyse la tonalit√© vocale de cet enregistrement audio. Retourne un JSON avec:
  - confidence: score de confiance entre 0 et 1
  - emotion: √©motion dominante (joyeux, triste, en col√®re, neutre, enthousiaste, calme, √©nergique, stress√©, confiant)
  - pace: d√©bit vocal (lent, mod√©r√©, rapide)
  - clarity: clart√© vocale (faible, moyenne, bonne, excellente)
  - energy: niveau d'√©nergie (faible, moyen, √©lev√©)
  - suggestions: 3 suggestions pour am√©liorer la communication

  R√©ponds UNIQUEMENT en JSON, sans autres textes.
  Exemple de r√©ponse: 
  {
    "confidence": 0.85,
    "emotion": "enthousiaste",
    "pace": "mod√©r√©",
    "clarity": "bonne",
    "energy": "√©lev√©",
    "suggestions": [
      "Ton enthousiasme est contagieux",
      "Le d√©bit est parfait pour la compr√©hension",
      "Continue √† varier les intonations"
    ]
  }
  `

  const response = await fetch('https://api.groq.com/openai/v1/chat/completions', {
    method: 'POST',
    headers: {
      'Authorization': `Bearer ${GROQ_API_KEY}`,
      'Content-Type': 'application/json',
    },
    body: JSON.stringify({
      messages: [
        {
          role: 'system',
          content: 'Tu es un expert en analyse vocale et communication. Tu r√©ponds uniquement en JSON valide.'
        },
        {
          role: 'user',
          content: `${prompt}\n\nAudio (base64): ${audioBase64.substring(0, 500)}...`
        }
      ],
      model: 'llama-3.1-8b-instant',
      temperature: 0.3,
      max_tokens: 500,
      response_format: { type: 'json_object' },
      stream: false
    })
  })

  if (!response.ok) {
    throw new Error(`API Groq: ${response.status} - ${response.statusText}`)
  }

  const result = await response.json()
  const analysis = JSON.parse(result.choices[0].message.content)

  console.log('‚úÖ Analyse Groq r√©ussie:', analysis)
  return analysis
}

// ‚úÖ ANALYSE AVEC GOOGLE AI STUDIO (Backup)
async function analyzeWithGoogleAI(audioFile) {
  const GOOGLE_API_KEY = Deno.env.get('GOOGLE_AI_STUDIO_API_KEY')
  
  if (!GOOGLE_API_KEY) {
    throw new Error('Cl√© Google non configur√©e')
  }

  const response = await fetch(
    `https://generativelanguage.googleapis.com/v1beta/models/gemini-pro:generateContent?key=${GOOGLE_API_KEY}`,
    {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
      },
      body: JSON.stringify({
        contents: [{
          parts: [{
            text: `Analyse la description suivante d'un enregistrement audio et retourne un JSON d'analyse de tonalit√©:
            
            Dur√©e: ~2 minutes
            Format: Audio vocal
            Contexte: Communication personnelle
            
            Retourne UNIQUEMENT du JSON avec cette structure:
            {
              "confidence": 0.85,
              "emotion": "enthousiaste",
              "pace": "mod√©r√©", 
              "clarity": "bonne",
              "energy": "√©lev√©",
              "suggestions": [
                "Ton enthousiasme est contagieux",
                "Le d√©bit est parfait pour la compr√©hension",
                "Continue √† varier les intonations"
              ]
            }`
          }]
        }],
        generationConfig: {
          temperature: 0.2,
          maxOutputTokens: 500,
        }
      })
    }
  )

  if (!response.ok) {
    throw new Error(`API Google: ${response.statusText}`)
  }

  const result = await response.json()
  const text = result.candidates[0].content.parts[0].text
  
  // Extraire le JSON de la r√©ponse
  const jsonMatch = text.match(/\{[\s\S]*\}/)
  if (jsonMatch) {
    const analysis = JSON.parse(jsonMatch[0])
    console.log('‚úÖ Analyse Google AI r√©ussie:', analysis)
    return analysis
  } else {
    throw new Error('R√©ponse Google non JSON')
  }
}

// ‚úÖ ANALYSE DE BASE (Fallback)
function getBasicToneAnalysis() {
  const emotions = ['enthousiaste', 'neutre', 'calme', '√©nergique', 'confiant']
  const paces = ['lent', 'mod√©r√©', 'rapide']
  const clarities = ['bonne', 'excellente', 'moyenne']
  
  return {
    confidence: 0.7 + Math.random() * 0.3,
    emotion: emotions[Math.floor(Math.random() * emotions.length)],
    pace: paces[Math.floor(Math.random() * paces.length)],
    clarity: clarities[Math.floor(Math.random() * clarities.length)],
    energy: ['faible', 'moyen', '√©lev√©'][Math.floor(Math.random() * 3)],
    suggestions: [
      'Ton vocal est bien √©quilibr√©',
      'Le d√©bit est adapt√© √† la communication',
      'Continue √† pratiquer pour gagner en confiance'
    ]
  }
}

// ‚úÖ FONCTION UTILITAIRE: Conversion ArrayBuffer vers Base64
function arrayBufferToBase64(buffer) {
  let binary = ''
  const bytes = new Uint8Array(buffer)
  const len = bytes.byteLength
  for (let i = 0; i < len; i++) {
    binary += String.fromCharCode(bytes[i])
  }
  return btoa(binary)
}
