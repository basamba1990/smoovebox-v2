// supabase/functions/analyze-tone/index.ts
import { createClient } from 'npm:@supabase/supabase-js@2.39.3'
import OpenAI from 'npm:openai@4.28.0'

const corsHeaders = {
  'Access-Control-Allow-Origin': '*',
  'Access-Control-Allow-Headers': 'authorization, x-client-info, apikey, content-type',
  'Access-Control-Allow-Methods': 'POST, OPTIONS'
}

// ‚úÖ ANALYSE DE TONALIT√â AVANC√âE AVEC GPT-4
const TONE_ANALYSIS_PROMPTS = {
  fr: `Analyse la tonalit√© √©motionnelle et vocale de cet audio. R√©ponds en JSON avec cette structure :

{
  "confidence": 0.85,
  "emotion": "joyeux/triste/col√©rique/neutre/enthousiaste/calme/√©nergique/stress√©/confiant/serein",
  "pace": "lent/moder√©/rapide",
  "clarity": "faible/moyen/bon/excellent",
  "energy": "faible/moyen/√©lev√©",
  "sentiment_score": 0.75,
  "vocal_characteristics": {
    "pitch_stability": "stable/variable",
    "articulation": "pr√©cise/rel√¢ch√©e",
    "intonation": "monotone/expressif",
    "pause_frequency": "rare/fr√©quent"
  },
  "emotional_intensity": 0.7,
  "communication_style": "formel/informel/amical/autoritaire",
  "improvement_suggestions": [
    "Suggestion 1 pour am√©liorer le ton",
    "Suggestion 2 pour l'impact vocal"
  ],
  "positive_aspects": [
    "Aspect positif 1",
    "Aspect positif 2"
  ]
}

Texte √† analyser : {text}`,

  en: `Analyze the emotional and vocal tone of this audio. Respond in JSON with this structure:

{
  "confidence": 0.85,
  "emotion": "joyful/sad/angry/neutral/enthusiastic/calm/energetic/stressed/confident/serene",
  "pace": "slow/moderate/fast",
  "clarity": "poor/average/good/excellent",
  "energy": "low/medium/high",
  "sentiment_score": 0.75,
  "vocal_characteristics": {
    "pitch_stability": "stable/variable",
    "articulation": "precise/relaxed",
    "intonation": "monotone/expressive",
    "pause_frequency": "rare/frequent"
  },
  "emotional_intensity": 0.7,
  "communication_style": "formal/informal/friendly/authoritative",
  "improvement_suggestions": [
    "Suggestion 1 to improve tone",
    "Suggestion 2 for vocal impact"
  ],
  "positive_aspects": [
    "Positive aspect 1",
    "Positive aspect 2"
  ]
}

Text to analyze: {text}`,

  ar: `ÿ≠ŸÑŸÑ ÿßŸÑŸÜÿ®ÿ±ÿ© ÿßŸÑÿπÿßÿ∑ŸÅŸäÿ© ŸàÿßŸÑÿµŸàÿ™Ÿäÿ© ŸÑŸáÿ∞ÿß ÿßŸÑÿµŸàÿ™. ÿ£ÿ¨ÿ® ÿ®ÿ™ŸÜÿ≥ŸäŸÇ JSON ŸÖÿπ Ÿáÿ∞Ÿá ÿßŸÑÿ®ŸÜŸäÿ©:

{
  "confidence": 0.85,
  "emotion": "ŸÅÿ±ÿ≠/ÿ≠ÿ≤ŸÜ/ÿ∫ÿ∂ÿ®/ŸÖÿ≠ÿßŸäÿØ/ŸÖÿ™ÿ≠ŸÖÿ≥/ŸáÿßÿØÿ¶/ŸÜÿ¥Ÿäÿ∑/ŸÖÿ™Ÿàÿ™ÿ±/Ÿàÿßÿ´ŸÇ/ŸÖÿ∑ŸÖÿ¶ŸÜ",
  "pace": "ÿ®ÿ∑Ÿäÿ°/ŸÖÿπÿ™ÿØŸÑ/ÿ≥ÿ±Ÿäÿπ",
  "clarity": "ÿ∂ÿπŸäŸÅ/ŸÖÿ™Ÿàÿ≥ÿ∑/ÿ¨ŸäÿØ/ŸÖŸÖÿ™ÿßÿ≤",
  "energy": "ŸÖŸÜÿÆŸÅÿ∂/ŸÖÿ™Ÿàÿ≥ÿ∑/ŸÖÿ±ÿ™ŸÅÿπ",
  "sentiment_score": 0.75,
  "vocal_characteristics": {
    "pitch_stability": "ÿ´ÿßÿ®ÿ™/ŸÖÿ™ÿ∫Ÿäÿ±",
    "articulation": "Ÿàÿßÿ∂ÿ≠/ŸÖÿ±ÿ™ÿÆŸä",
    "intonation": "ÿ±ÿ™Ÿäÿ®/ŸÖÿπÿ®ÿ±",
    "pause_frequency": "ŸÇŸÑŸäŸÑ/ŸÉÿ´Ÿäÿ±"
  },
  "emotional_intensity": 0.7,
  "communication_style": "ÿ±ÿ≥ŸÖŸä/ÿ∫Ÿäÿ± ÿ±ÿ≥ŸÖŸä/ŸàÿØŸä/ÿ≥ŸÑÿ∑ŸàŸä",
  "improvement_suggestions": [
    "ÿßŸÇÿ™ÿ±ÿßÿ≠ 1 ŸÑÿ™ÿ≠ÿ≥ŸäŸÜ ÿßŸÑŸÜÿ®ÿ±ÿ©",
    "ÿßŸÇÿ™ÿ±ÿßÿ≠ 2 ŸÑŸÑÿ™ÿ£ÿ´Ÿäÿ± ÿßŸÑÿµŸàÿ™Ÿä"
  ],
  "positive_aspects": [
    "ÿßŸÑÿ¨ÿßŸÜÿ® ÿßŸÑÿ•Ÿäÿ¨ÿßÿ®Ÿä 1",
    "ÿßŸÑÿ¨ÿßŸÜÿ® ÿßŸÑÿ•Ÿäÿ¨ÿßÿ®Ÿä 2"
  ]
}

ÿßŸÑŸÜÿµ ÿßŸÑŸÖÿ±ÿßÿØ ÿ™ÿ≠ŸÑŸäŸÑŸá: {text}`
}

Deno.serve(async (req) => {
  console.log("üéµ Fonction analyze-tone appel√©e")

  // ‚úÖ GESTION CORS
  if (req.method === 'OPTIONS') {
    return new Response('ok', { 
      headers: {
        ...corsHeaders,
        'Access-Control-Max-Age': '86400',
      }
    })
  }

  try {
    // ‚úÖ VALIDATION DE LA M√âTHODE
    if (req.method !== 'POST') {
      return new Response(
        JSON.stringify({ error: 'M√©thode non autoris√©e' }),
        { 
          status: 405, 
          headers: { ...corsHeaders, 'Content-Type': 'application/json' } 
        }
      )
    }

    // ‚úÖ PARSING DU CORPS
    let requestBody
    try {
      requestBody = await req.json()
    } catch (parseError) {
      return new Response(
        JSON.stringify({ error: 'Corps JSON invalide' }),
        { 
          status: 400, 
          headers: { ...corsHeaders, 'Content-Type': 'application/json' } 
        }
      )
    }

    const { audio, userId, language = 'fr' } = requestBody

    // ‚úÖ VALIDATION
    if (!audio) {
      return new Response(
        JSON.stringify({ error: 'Donn√©es audio manquantes' }),
        { 
          status: 400, 
          headers: { ...corsHeaders, 'Content-Type': 'application/json' } 
        }
      )
    }

    // ‚úÖ R√âCUP√âRATION DES CL√âS
    const openaiApiKey = Deno.env.get('OPENAI_API_KEY')
    if (!openaiApiKey) {
      return new Response(
        JSON.stringify({ error: 'Cl√© API OpenAI manquante' }),
        { 
          status: 500, 
          headers: { ...corsHeaders, 'Content-Type': 'application/json' } 
        }
      )
    }

    const openai = new OpenAI({ apiKey: openaiApiKey })

    console.log("ü§ñ Analyse de tonalit√© avec GPT-4...")

    // ‚úÖ TRANSCRIPTION AUDIO AVEC WHISPER (si audio fourni)
    let transcriptionText = audio
    if (typeof audio !== 'string') {
      // Si c'est un blob audio, le transcrire d'abord
      try {
        const transcription = await openai.audio.transcriptions.create({
          file: audio,
          model: "whisper-1",
          language: language,
          response_format: "text"
        })
        transcriptionText = transcription
      } catch (transcribeError) {
        console.error('‚ùå Erreur transcription:', transcribeError)
        return new Response(
          JSON.stringify({ error: 'Erreur lors de la transcription audio' }),
          { 
            status: 500, 
            headers: { ...corsHeaders, 'Content-Type': 'application/json' } 
          }
        )
      }
    }

    if (!transcriptionText || transcriptionText.trim().length < 10) {
      return new Response(
        JSON.stringify({ error: 'Texte de transcription trop court ou vide' }),
        { 
          status: 400, 
          headers: { ...corsHeaders, 'Content-Type': 'application/json' } 
        }
      )
    }

    // ‚úÖ ANALYSE DE TONALIT√â AVEC GPT-4
    const promptTemplate = TONE_ANALYSIS_PROMPTS[language] || TONE_ANALYSIS_PROMPTS.fr
    const analysisPrompt = promptTemplate.replace('{text}', transcriptionText.substring(0, 4000))

    const completion = await openai.chat.completions.create({
      model: "gpt-4", // ‚úÖ UTILISATION DE GPT-4 POUR MEILLEURE ANALYSE
      messages: [
        {
          role: "system",
          content: "Tu es un expert en analyse vocale et √©motionnelle. Tu analyses les transcriptions pour d√©tecter la tonalit√©, les √©motions et les caract√©ristiques vocales. Tes analyses sont pr√©cises et constructives."
        },
        {
          role: "user",
          content: analysisPrompt
        }
      ],
      max_tokens: 1500,
      temperature: 0.3,
      response_format: { type: "json_object" }
    })

    const analysisText = completion.choices[0].message.content
    let toneAnalysis

    try {
      toneAnalysis = JSON.parse(analysisText)
      
      // ‚úÖ ENRICHISSEMENT DES DONN√âES
      toneAnalysis.analyzed_at = new Date().toISOString()
      toneAnalysis.text_length = transcriptionText.length
      toneAnalysis.model_used = "gpt-4"
      toneAnalysis.language = language

    } catch (parseError) {
      console.error('‚ùå Erreur parsing analyse:', parseError)
      // Fallback analysis
      toneAnalysis = {
        confidence: 0.7,
        emotion: "neutre",
        pace: "mod√©r√©",
        clarity: "bon",
        energy: "moyen",
        sentiment_score: 0.65,
        vocal_characteristics: {
          pitch_stability: "stable",
          articulation: "pr√©cise",
          intonation: "expressif",
          pause_frequency: "mod√©r√©"
        },
        emotional_intensity: 0.6,
        communication_style: "amical",
        improvement_suggestions: [
          "Continuez √† parler avec cette clart√©",
          "Variez l√©g√®rement le d√©bit pour plus d'impact"
        ],
        positive_aspects: [
          "Ton authentique et engageant",
          "Bonne articulation des mots"
        ],
        analyzed_at: new Date().toISOString(),
        text_length: transcriptionText.length,
        model_used: "gpt-4",
        language: language
      }
    }

    console.log("‚úÖ Analyse de tonalit√© termin√©e")

    return new Response(
      JSON.stringify({ 
        success: true, 
        message: 'Analyse de tonalit√© termin√©e avec succ√®s',
        analysis: toneAnalysis,
        text_sample: transcriptionText.substring(0, 200) + '...'
      }),
      { 
        status: 200, 
        headers: { ...corsHeaders, 'Content-Type': 'application/json' } 
      }
    )

  } catch (error) {
    console.error('‚ùå Erreur analyse-tone:', error)
    return new Response(
      JSON.stringify({ 
        error: 'Erreur lors de l\'analyse de tonalit√©', 
        details: error.message
      }),
      { 
        status: 500, 
        headers: { ...corsHeaders, 'Content-Type': 'application/json' } 
      }
    )
  }
})
