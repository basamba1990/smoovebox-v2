import { createClient } from 'npm:@supabase/supabase-js@2.39.3'
import OpenAI from 'npm:openai@4.28.0'

const VIDEO_STATUS = { 
  UPLOADED: 'uploaded', 
  PROCESSING: 'processing', 
  TRANSCRIBED: 'transcribed', 
  ANALYZING: 'analyzing', 
  ANALYZED: 'analyzed', 
  PUBLISHED: 'published', 
  FAILED: 'failed' 
}

const corsHeaders = { 
  'Access-Control-Allow-Origin': '*', 
  'Access-Control-Allow-Headers': 'authorization, x-client-info, apikey, content-type', 
  'Access-Control-Allow-Methods': 'POST, OPTIONS' 
}

// ‚úÖ SUPPORT MULTILINGUE √âTENDU
const SUPPORTED_LANGUAGES = {
  'fr': 'French',
  'en': 'English',
  'es': 'Spanish',
  'de': 'German',
  'it': 'Italian',
  'pt': 'Portuguese',
  'ru': 'Russian',
  'zh': 'Chinese',
  'ja': 'Japanese',
  'ko': 'Korean',
  'ar': 'Arabic',
  'hi': 'Hindi',
  'tr': 'Turkish',
  'nl': 'Dutch',
  'pl': 'Polish',
  'sv': 'Swedish',
  'da': 'Danish',
  'no': 'Norwegian',
  'fi': 'Finnish',
  'el': 'Greek',
  'he': 'Hebrew',
  'th': 'Thai',
  'vi': 'Vietnamese'
};

// ‚úÖ D√âTECTION AUTOMATIQUE DE LANGUE AVEC WHISPER
const WHISPER_LANGUAGE_MAPPING = {
  'fr': 'french',
  'en': 'english',
  'es': 'spanish',
  'de': 'german',
  'it': 'italian',
  'pt': 'portuguese',
  'ru': 'russian',
  'zh': 'chinese',
  'ja': 'japanese',
  'ko': 'korean',
  'ar': 'arabic',
  'hi': 'hindi',
  'tr': 'turkish',
  'nl': 'dutch',
  'pl': 'polish',
  'sv': 'swedish',
  'da': 'danish',
  'no': 'norwegian',
  'fi': 'finnish',
  'el': 'greek',
  'he': 'hebrew',
  'th': 'thai',
  'vi': 'vietnamese'
};

Deno.serve(async (req) => {
  console.log("üé§ transcribe-video (multilingue) appel√©e");

  if (req.method === 'OPTIONS') {
    return new Response('ok', { headers: corsHeaders })
  }

  let videoId = null;

  try {
    console.log("üì® Headers:", Object.fromEntries(req.headers));
    
    const { videoId: vidId, userId, videoUrl, preferredLanguage, autoDetectLanguage = true } = await req.json();
    videoId = vidId;

    console.log("üì¶ Param√®tres re√ßus:", { 
      videoId, 
      userId, 
      videoUrl: videoUrl ? videoUrl.substring(0, 100) + "..." : "NULL",
      preferredLanguage,
      autoDetectLanguage
    });

    // ‚úÖ VALIDATION AM√âLIOR√âE
    if (!videoId || !userId || !videoUrl) {
      throw new Error('Param√®tres manquants: videoId, userId, videoUrl requis');
    }

    try {
      new URL(videoUrl);
    } catch (urlError) {
      throw new Error(`URL vid√©o invalide: ${videoUrl}. Erreur: ${urlError.message}`);
    }

    const supabaseUrl = Deno.env.get('SUPABASE_URL');
    const supabaseServiceKey = Deno.env.get('SUPABASE_SERVICE_ROLE_KEY');
    const openaiApiKey = Deno.env.get('OPENAI_API_KEY');

    if (!supabaseUrl || !supabaseServiceKey) {
      throw new Error('Configuration Supabase manquante');
    }
    if (!openaiApiKey) {
      throw new Error('Cl√© API OpenAI manquante');
    }

    const supabase = createClient(supabaseUrl, supabaseServiceKey);
    const openai = new OpenAI({ apiKey: openaiApiKey });

    // ‚úÖ MISE √Ä JOUR AVEC INFORMATIONS DE LANGUE
    console.log("üîÑ Mise √† jour statut PROCESSING");
    const { error: statusError } = await supabase
      .from('videos')
      .update({ 
        status: VIDEO_STATUS.PROCESSING,
        transcription_language: preferredLanguage || 'auto',
        updated_at: new Date().toISOString()
      })
      .eq('id', videoId)

    if (statusError) {
      throw new Error(`Erreur mise √† jour statut: ${statusError.message}`);
    }

    console.log('üéôÔ∏è D√©but transcription multilingue pour la vid√©o:', videoId);
    console.log("üåê Param√®tres langue:", { preferredLanguage, autoDetectLanguage });

    // ‚úÖ T√âL√âCHARGEMENT AVEC GESTION MULTILANGUE
    console.log("üì• T√©l√©chargement vid√©o...");
    const videoResponse = await fetch(videoUrl, {
      headers: {
        'User-Agent': 'SpotBulle-Multilingual-Transcription/2.0'
      }
    });
    
    if (!videoResponse.ok) {
      const errorText = await videoResponse.text();
      throw new Error(`Erreur t√©l√©chargement vid√©o: ${videoResponse.status} ${videoResponse.statusText}. D√©tails: ${errorText}`);
    }

    const videoBlob = await videoResponse.blob();
    console.log(`üìä Taille vid√©o t√©l√©charg√©e: ${videoBlob.size} bytes`);

    if (videoBlob.size === 0) {
      throw new Error('Fichier vid√©o vide ou inaccessible');
    }

    // ‚úÖ CONFIGURATION WHISPER MULTILINGUE
    const whisperConfig = {
      file: new File([videoBlob], `video-${videoId}.mp4`, { 
        type: 'video/mp4' 
      }),
      model: 'whisper-1',
      response_format: 'verbose_json'
    };

    // ‚úÖ AJOUT DU PARAM√àTRE LANGUE SI SP√âCIFI√â
    if (preferredLanguage && WHISPER_LANGUAGE_MAPPING[preferredLanguage]) {
      whisperConfig.language = WHISPER_LANGUAGE_MAPPING[preferredLanguage];
      console.log(`üéØ Transcription en langue sp√©cifi√©e: ${SUPPORTED_LANGUAGES[preferredLanguage]}`);
    } else if (!autoDetectLanguage) {
      // D√©tection automatique d√©sactiv√©e, utiliser l'anglais par d√©faut
      whisperConfig.language = 'english';
      console.log("üîç D√©tection auto d√©sactiv√©e, utilisation de l'anglais par d√©faut");
    } else {
      console.log("üåê D√©tection automatique de la langue activ√©e");
    }

    // ‚úÖ TRANSCRIPTION AVEC WHISPER
    console.log("ü§ñ Appel Whisper multilingue...");
    const transcriptionResponse = await openai.audio.transcriptions.create(whisperConfig);

    const transcriptionText = transcriptionResponse.text;
    const detectedLanguage = transcriptionResponse.language || preferredLanguage || 'fr';
    
    console.log(`‚úÖ Transcription r√©ussie - Langue: ${detectedLanguage}, Longueur: ${transcriptionText.length}`);

    const transcriptionData = {
      text: transcriptionText,
      language: detectedLanguage,
      language_name: SUPPORTED_LANGUAGES[detectedLanguage] || 'Unknown',
      duration: transcriptionResponse.duration,
      words: transcriptionResponse.words || [],
      confidence: transcriptionResponse.confidence || 0.8,
      detected_automatically: !preferredLanguage && autoDetectLanguage
    };

    // ‚úÖ SAUVEGARDE AVEC INFORMATIONS LANGUE
    console.log("üíæ Sauvegarde transcription multilingue...");
    const updatePayload = {
      status: VIDEO_STATUS.TRANSCRIBED,
      transcription_text: transcriptionText,
      transcription_data: transcriptionData,
      transcription_language: detectedLanguage,
      updated_at: new Date().toISOString()
    };

    const { error: updateError } = await supabase
      .from('videos')
      .update(updatePayload)
      .eq('id', videoId)

    if (updateError) {
      console.warn("‚ö†Ô∏è Erreur sauvegarde colonne langue, tentative sans...");
      // Fallback sans la colonne language
      const { error: fallbackError } = await supabase
        .from('videos')
        .update({
          status: VIDEO_STATUS.TRANSCRIBED,
          transcription_text: transcriptionText,
          transcription_data: transcriptionData,
          updated_at: new Date().toISOString()
        })
        .eq('id', videoId);

      if (fallbackError) {
        throw new Error(`Erreur mise √† jour transcription: ${fallbackError.message}`);
      }
    }

    // ‚úÖ D√âCLENCHEMENT ANALYSE MULTILINGUE
    console.log("üöÄ D√©clenchement analyse multilingue...");
    try {
      const analyzeResponse = await fetch(`${supabaseUrl}/functions/v1/analyze-transcription`, {
        method: 'POST',
        headers: {
          'Authorization': `Bearer ${supabaseServiceKey}`,
          'Content-Type': 'application/json',
        },
        body: JSON.stringify({
          videoId,
          transcriptionText,
          userId,
          transcriptionLanguage: detectedLanguage // ‚úÖ Passage de la langue pour l'analyse
        })
      });

      if (!analyzeResponse.ok) {
        const errorText = await analyzeResponse.text();
        console.warn('‚ö†Ô∏è Erreur d√©clenchement analyse:', errorText);
      } else {
        console.log('‚úÖ Analyse multilingue d√©clench√©e avec succ√®s');
      }
    } catch (analyzeError) {
      console.warn('‚ö†Ô∏è Erreur lors du d√©clenchement de l\'analyse:', analyzeError);
    }

    return new Response(
      JSON.stringify({ 
        success: true, 
        message: 'Transcription multilingue termin√©e avec succ√®s',
        transcriptionLength: transcriptionText.length,
        language: detectedLanguage,
        languageName: SUPPORTED_LANGUAGES[detectedLanguage] || 'Inconnue'
      }),
      { 
        status: 200, 
        headers: { ...corsHeaders, 'Content-Type': 'application/json' } 
      }
    )

  } catch (error) {
    console.error('‚ùå Erreur transcription multilingue:', error);

    // Mettre √† jour le statut d'erreur si videoId est disponible
    if (videoId) {
      try {
        const supabaseUrl = Deno.env.get('SUPABASE_URL');
        const supabaseServiceKey = Deno.env.get('SUPABASE_SERVICE_ROLE_KEY');
        
        if (supabaseUrl && supabaseServiceKey) {
          const supabase = createClient(supabaseUrl, supabaseServiceKey);
          await supabase
            .from('videos')
            .update({ 
              status: VIDEO_STATUS.FAILED,
              error_message: error.message,
              updated_at: new Date().toISOString()
            })
            .eq('id', videoId)
        }
      } catch (updateError) {
        console.error('‚ùå Erreur mise √† jour statut erreur:', updateError);
      }
    }

    return new Response(
      JSON.stringify({ 
        error: 'Erreur lors de la transcription multilingue', 
        details: error.message,
        supportedLanguages: Object.keys(SUPPORTED_LANGUAGES)
      }),
      { 
        status: 500, 
        headers: { ...corsHeaders, 'Content-Type': 'application/json' } 
      }
    )
  }
})
